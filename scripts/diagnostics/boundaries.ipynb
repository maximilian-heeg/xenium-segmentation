{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pylab as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "import numpy as np\n",
    "import warnings\n",
    "import geopandas as gpd\n",
    "import tifffile\n",
    "import os\n",
    "import json\n",
    "from fast_alphashape import alphashape\n",
    "from shapely.ops import transform\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_files() -> pd.DataFrame:\n",
    "    df_nuclear = pd.read_csv(\"data/transcripts_cellpose.csv\")\n",
    "    df_baysor = pd.read_csv(\"data/transcripts.csv\")\n",
    "    df_nuclear = df_nuclear[['transcript_id', 'cell_id']]\n",
    "    df = pd.merge(left=df_baysor, right=df_nuclear, how=\"left\", left_on=\"transcript_id\", right_on='transcript_id')\n",
    "    return df\n",
    "\n",
    "df = import_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_image(path: str):\n",
    "    file = os.path.join(path, \"morphology_mip.ome.tif\")\n",
    "    img = tifffile.imread(file)\n",
    "    return img\n",
    "\n",
    "img = import_image(\"data/xenium\")\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pixel_size(path: str) -> float:\n",
    "    file = open(os.path.join(path, \"experiment.xenium\"))\n",
    "    experiment = json.load(file)\n",
    "    pixel_size = experiment['pixel_size']\n",
    "    return pixel_size\n",
    "\n",
    "pixel_size = get_pixel_size(\"data/xenium\")\n",
    "pixel_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subset to a smaller FOV\n",
    "\n",
    "Larger slides might take a long time to plot and the image would be too crowded to actually see the boundaries. Hence, we subset it to a smaller field of view (FOV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.getenv(\"HEIGHT\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_width = int(os.getenv(\"WIDTH\"))\n",
    "max_height = int(os.getenv(\"HEIGHT\"))\n",
    "\n",
    "x_offset = int(os.getenv(\"X_OFFSET\"))\n",
    "y_offset = int(os.getenv(\"Y_OFFSET\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check boundaries\n",
    "if max_width > img.shape[1]:\n",
    "    max_width = img.shape[1]\n",
    "    x_offset = 0\n",
    "if max_height > img.shape[0]:\n",
    "    max_height = img.shape[0]\n",
    "    y_offset = 0\n",
    "\n",
    "if (x_offset < 0) and (img.shape[1] > max_width):\n",
    "    x_offset = round(img.shape[1] /2 - max_width /2)\n",
    "if (max_width + x_offset) > img.shape[1]:\n",
    "    x_offset = img.shape[1] - max_width\n",
    "\n",
    "if (y_offset < 0) and (img.shape[0] > max_height):\n",
    "    y_offset = round(img.shape[0] /2 - max_height /2)\n",
    "if (max_height + y_offset) > img.shape[0]:\n",
    "    y_offset = img.shape[0] - max_height\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (8,6))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.imshow(\n",
    "    img,\n",
    "    vmin=np.percentile(img, 99)*0.1,\n",
    "    vmax=np.percentile(img, 99)*1.1,\n",
    "    cmap=sns.dark_palette(\"#bfcee3\", reverse=False, as_cmap=True)\n",
    ")\n",
    "img_size = Rectangle((0,0),img.shape[1], img.shape[0], edgecolor='b', facecolor='none')\n",
    "fov = Rectangle((x_offset, y_offset), max_width, max_height, edgecolor='r', facecolor='none')\n",
    "ax.add_patch(img_size)\n",
    "ax.add_patch(fov)\n",
    "ax.set_xlim((0, img.shape[1]))\n",
    "ax.set_ylim((img.shape[0], 0))\n",
    "plt.gca().set_aspect('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subset_fov(img, df, max_width, max_height):\n",
    "    img = img[y_offset:(y_offset+max_height), x_offset:(x_offset + max_width)]\n",
    "\n",
    "    df = df[\n",
    "        ((df.x / pixel_size) >= (x_offset - 20)) &\n",
    "        ((df.x / pixel_size) <= (x_offset + max_width + 20)) &\n",
    "        ((df.y / pixel_size) >= (y_offset - 20 )) &\n",
    "        ((df.y / pixel_size) <= (y_offset + max_height + 20))\n",
    "    ]\n",
    "\n",
    "    df.x = df.x - (x_offset * pixel_size)\n",
    "    df.y = df.y - (y_offset * pixel_size)\n",
    "    return (img, df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(img, df) = subset_fov(img, df, max_width, max_height)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create cell boundaries\n",
    "\n",
    "Using alphashapes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_alphashape(points: pd.DataFrame, alpha: float):\n",
    "    points = np.array(points)\n",
    "    shape = alphashape(points, alpha=alpha)\n",
    "    return shape\n",
    "\n",
    "shapes = df[~pd.isnull(df.cell)].groupby(\"cell\")[['x', 'y']].apply(make_alphashape, alpha=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapes = gpd.GeoSeries(shapes)\n",
    "shapes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_to_image(x, y):\n",
    "    return(x/pixel_size, y/pixel_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (15,15))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.imshow(\n",
    "    img,\n",
    "    vmin=np.percentile(img, 99)*0.1,\n",
    "    vmax=np.percentile(img, 99)*1.1,\n",
    "    cmap=sns.dark_palette(\"#bfcee3\", reverse=False, as_cmap=True)\n",
    ")\n",
    "\n",
    "ax.set_xlim((0, img.shape[1]))\n",
    "ax.set_ylim((img.shape[0], 0))\n",
    "\n",
    "colors = sns.color_palette()[3]\n",
    "shapes.apply(lambda x: transform(scale_to_image, x)).plot(facecolor=colors, edgecolor='none', alpha=0.2, ax=ax)\n",
    "shapes.apply(lambda x: transform(scale_to_image, x)).plot(facecolor=\"none\", edgecolor=colors, alpha=0.7,  ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
